{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Attention.ipynb","provenance":[{"file_id":"11ZCL_l3YnTUHGbA1FBMEbavyu7LUrqgX","timestamp":1597335908999},{"file_id":"1-virH5eoLhntdlzQejTsUsO0undnzkrR","timestamp":1594813661497},{"file_id":"1k6NgvMVYkz07WDXLcS84XulCHmCdV2je","timestamp":1594515484374},{"file_id":"1GkySQlBY9x2Qft9q5ENyLrZerizdfiRq","timestamp":1593300375713}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qHWBoJA3KA53","executionInfo":{"status":"ok","timestamp":1601493111308,"user_tz":240,"elapsed":725,"user":{"displayName":"Richard Watson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_aaSfAKowaEMKH5EBs_BIRHzGivNQen-5Osb-=s64","userId":"11605160484643735164"}},"outputId":"2ad268d6-0d47-4fd8-e503-4bb3df4732aa","colab":{"base_uri":"https://localhost:8080/","height":364}},"source":["# This ensures that a gpu is being used by the current google colab session.\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wed Sep 30 19:11:50 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    24W / 300W |      0MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zLd2Yfk653Gu","executionInfo":{"status":"ok","timestamp":1601493137674,"user_tz":240,"elapsed":27071,"user":{"displayName":"Richard Watson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_aaSfAKowaEMKH5EBs_BIRHzGivNQen-5Osb-=s64","userId":"11605160484643735164"}},"outputId":"5b91ed8e-3b39-4d88-aae9-12c2e5e0897b","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# This code block is used to access your google drive\n","\n","from google.colab import drive\n","ROOT = \"/content/drive\"\n","drive.mount(ROOT)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CwHxwKkL6qh3","executionInfo":{"status":"ok","timestamp":1601493137681,"user_tz":240,"elapsed":27066,"user":{"displayName":"Richard Watson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_aaSfAKowaEMKH5EBs_BIRHzGivNQen-5Osb-=s64","userId":"11605160484643735164"}},"outputId":"a421e731-5eb7-42db-8bca-9aaab47535f6","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Make sure this points to the project folder\n","\n","%cd drive/'My Drive'/CORL"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab_Workspace\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZQXpBJPg0-V1"},"source":["%cd attention"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6pplMLCu-M8m","executionInfo":{"status":"ok","timestamp":1601493142004,"user_tz":240,"elapsed":31368,"user":{"displayName":"Richard Watson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_aaSfAKowaEMKH5EBs_BIRHzGivNQen-5Osb-=s64","userId":"11605160484643735164"}},"outputId":"adc05c5f-b6be-47fc-fd08-fc3380ebd7e8","colab":{"base_uri":"https://localhost:8080/","height":211}},"source":["# install dependencies\n","!pip install tensorboard_logger"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorboard_logger\n","  Downloading https://files.pythonhosted.org/packages/87/7a/ec0fd26dba69191f82eb8f38f5b401c124f45a207490a7ade6ea9717ecdb/tensorboard_logger-0.1.0-py2.py3-none-any.whl\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (7.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (1.18.5)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (1.4.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (3.12.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboard_logger) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->tensorboard_logger) (50.3.0)\n","Installing collected packages: tensorboard-logger\n","Successfully installed tensorboard-logger-0.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3cgIK0U5M26a","executionInfo":{"status":"ok","timestamp":1601493271045,"user_tz":240,"elapsed":81871,"user":{"displayName":"Richard Watson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_aaSfAKowaEMKH5EBs_BIRHzGivNQen-5Osb-=s64","userId":"11605160484643735164"}},"outputId":"d0613b90-866e-4c5a-cf54-34d963b8f996","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# This block will run the originial attention code with the below settings\n","# The save_hrs are the checkpoint hours to save the model\n","\n","!python run.py --graph_size 100 --batch_size 64 --problem cvrp --baseline rollout --run_name 'vrp100_rollout' --save_hrs 20 10"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-09-30 19:13:10.377615: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","{'baseline': 'rollout',\n"," 'batch_size': 64,\n"," 'bl_alpha': 0.05,\n"," 'bl_warmup_epochs': 1,\n"," 'checkpoint_encoder': False,\n"," 'checkpoint_epochs': 1,\n"," 'data_distribution': None,\n"," 'embedding_dim': 128,\n"," 'epoch_size': 1280000,\n"," 'epoch_start': 0,\n"," 'eval_batch_size': 1024,\n"," 'eval_only': False,\n"," 'exp_beta': 0.8,\n"," 'graph_size': 100,\n"," 'hidden_dim': 128,\n"," 'load_path': None,\n"," 'log_dir': 'logs',\n"," 'log_step': 50,\n"," 'lr_critic': 0.0001,\n"," 'lr_decay': 1.0,\n"," 'lr_model': 0.0001,\n"," 'max_grad_norm': 1.0,\n"," 'model': 'attention',\n"," 'n_encode_layers': 3,\n"," 'n_epochs': 100,\n"," 'no_cuda': False,\n"," 'no_progress_bar': False,\n"," 'no_tensorboard': False,\n"," 'normalization': 'batch',\n"," 'output_dir': 'outputs',\n"," 'problem': 'cvrp',\n"," 'resume': None,\n"," 'run_name': 'vrp100_rollout_20200930T191312',\n"," 'save_dir': 'outputs/cvrp_100/vrp100_rollout_20200930T191312',\n"," 'save_hrs': [9],\n"," 'seed': 1234,\n"," 'shrink_size': None,\n"," 'tanh_clipping': 10.0,\n"," 'use_cuda': True,\n"," 'val_dataset': None,\n"," 'val_size': 10000}\n","Evaluating baseline model on evaluation dataset\n","100% 10/10 [00:07<00:00,  1.36it/s]\n","Start train epoch 0, lr=0.0001 for run vrp100_rollout_20200930T191312\n","  0% 0/20000 [00:00<?, ?it/s]epoch: 0, train_batch_id: 0, avg_cost: 61.1080207824707\n","grad_norm: 1717.745361328125, clipped: 1.0\n","  0% 15/20000 [00:09<3:07:47,  1.77it/s]Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f3cb5f39908>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1101, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1067, in _shutdown_workers\n","    self._workers_done_event.set()\n","  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 346, in set\n","    with self._cond:\n","  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 230, in __enter__\n","    return self._lock.__enter__()\n","KeyboardInterrupt: \n","  0% 15/20000 [00:09<3:27:11,  1.61it/s]\n","Traceback (most recent call last):\n","  File \"run.py\", line 197, in <module>\n","    run(get_options())\n","  File \"run.py\", line 175, in run\n","    start_time\n","  File \"/content/drive/My Drive/Colab_Workspace/project_folder/attention/train.py\", line 96, in train_epoch\n","    opts\n","  File \"/content/drive/My Drive/Colab_Workspace/project_folder/attention/train.py\", line 146, in train_batch\n","    cost, log_likelihood = model(x)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/drive/My Drive/Colab_Workspace/project_folder/attention/nets/attention_model.py\", line 138, in forward\n","    _log_p, pi = self._inner(input, embeddings)\n","  File \"/content/drive/My Drive/Colab_Workspace/project_folder/attention/nets/attention_model.py\", line 253, in _inner\n","    log_p, mask = self._get_log_p(fixed, state)\n","  File \"/content/drive/My Drive/Colab_Workspace/project_folder/attention/nets/attention_model.py\", line 350, in _get_log_p\n","    self.project_step_context(self._get_parallel_step_context(fixed.node_embeddings, state))\n","  File \"/content/drive/My Drive/Colab_Workspace/project_folder/attention/nets/attention_model.py\", line 406, in _get_parallel_step_context\n","    -1\n","KeyboardInterrupt\n","^C\n"],"name":"stdout"}]}]}